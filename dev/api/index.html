<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · AugmentedGaussianProcesses.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>AugmentedGaussianProcesses.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li><a class="toctext" href="../background/">Background</a></li><li><a class="toctext" href="../userguide/">User Guide</a></li><li><a class="toctext" href="../kernel/">Kernels</a></li><li><a class="toctext" href="../examples/">Examples</a></li><li><a class="toctext" href="../comparison/">Other Julia GP Packages</a></li><li class="current"><a class="toctext" href>API</a><ul class="internal"><li><a class="toctext" href="#Module-1">Module</a></li><li><a class="toctext" href="#Model-Types-1">Model Types</a></li><li><a class="toctext" href="#Likelihood-Types-1">Likelihood Types</a></li><li><a class="toctext" href="#Inference-Types-1">Inference Types</a></li><li><a class="toctext" href="#Functions-and-methods-1">Functions and methods</a></li><li><a class="toctext" href="#Kernels-1">Kernels</a></li><li><a class="toctext" href="#Kernel-functions-1">Kernel functions</a></li><li><a class="toctext" href="#Index-1">Index</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>API</a></li></ul><a class="edit-page" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/master/docs/src/api.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>API</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="API-Library-1" href="#API-Library-1">API Library</a></h1><hr/><ul><li><a href="#API-Library-1">API Library</a></li><ul><li><a href="#Module-1">Module</a></li><li><a href="#Model-Types-1">Model Types</a></li><li><a href="#Likelihood-Types-1">Likelihood Types</a></li><li><a href="#Inference-Types-1">Inference Types</a></li><li><a href="#Functions-and-methods-1">Functions and methods</a></li><li><a href="#Kernels-1">Kernels</a></li><li><a href="#Kernel-functions-1">Kernel functions</a></li><li><a href="#Index-1">Index</a></li></ul></ul><h2><a class="nav-anchor" id="Module-1" href="#Module-1">Module</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.AugmentedGaussianProcesses" href="#AugmentedGaussianProcesses.AugmentedGaussianProcesses"><code>AugmentedGaussianProcesses.AugmentedGaussianProcesses</code></a> — <span class="docstring-category">Module</span>.</div><div><div><p>General Framework for the data augmented Gaussian Processes</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/AugmentedGaussianProcesses.jl#L1-L5">source</a></section><h2><a class="nav-anchor" id="Model-Types-1" href="#Model-Types-1">Model Types</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.GP" href="#AugmentedGaussianProcesses.GP"><code>AugmentedGaussianProcesses.GP</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Class for variational Gaussian Processes models (non-sparse)</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/models/GP.jl#L1">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.VGP" href="#AugmentedGaussianProcesses.VGP"><code>AugmentedGaussianProcesses.VGP</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Class for variational Gaussian Processes models (non-sparse)</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/models/VGP.jl#L1">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.SVGP" href="#AugmentedGaussianProcesses.SVGP"><code>AugmentedGaussianProcesses.SVGP</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Class for sparse variational Gaussian Processes </p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/models/SVGP.jl#L1">source</a></section><h2><a class="nav-anchor" id="Likelihood-Types-1" href="#Likelihood-Types-1">Likelihood Types</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.GaussianLikelihood" href="#AugmentedGaussianProcesses.GaussianLikelihood"><code>AugmentedGaussianProcesses.GaussianLikelihood</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Gaussian likelihood : <span>$p(y|f) = \mathcal{N}(y|f,\epsilon)$</span></p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/likelihood/gaussian.jl#L1-L3">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.StudentTLikelihood" href="#AugmentedGaussianProcesses.StudentTLikelihood"><code>AugmentedGaussianProcesses.StudentTLikelihood</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p><strong>Student-T likelihood</strong></p><p>Student-t likelihood for regression: <span>$\frac{\Gamma((\nu+1)/2)}{\sqrt{\nu\pi}\Gamma(\nu/2)}\left(1+t^2/\nu\right)^{(-(\nu+1)/2)}$</span> see <a href="https://en.wikipedia.org/wiki/Student%27s_t-distribution">wiki page</a></p><hr/><p>For the analytical solution, it is augmented via:</p><div>\[#TODO\]</div><p>See paper <a href="http://www.jmlr.org/papers/volume12/jylanki11a/jylanki11a.pdf">Robust Gaussian Process Regression with a Student-t Likelihood</a></p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/likelihood/studentt.jl#L1-L14">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.BayesianSVM" href="#AugmentedGaussianProcesses.BayesianSVM"><code>AugmentedGaussianProcesses.BayesianSVM</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>The <a href="https://arxiv.org/abs/1707.05532">Bayesian SVM</a> is a Bayesian interpretation of the classical SVM. By using an augmentation (Laplace) one gets a conditionally conjugate likelihood (see paper)</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/likelihood/bayesiansvm.jl#L1-L4">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.LogisticLikelihood" href="#AugmentedGaussianProcesses.LogisticLikelihood"><code>AugmentedGaussianProcesses.LogisticLikelihood</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p><strong>Logistic Likelihood</strong></p><p>Bernoulli likelihood with a logistic link for the Bernoulli likelihood     <span>$p(y|f) = \sigma(yf) = \frac{1}{1+\exp(-yf)}$</span>, (for more info see : <a href="https://en.wikipedia.org/wiki/Logistic_function">wiki page</a>)</p><pre><code class="language-none">---

For the analytic versionm the likelihood is augmented to give a conditionally conjugate likelihood :
```math
p(y|f,\omega) = \exp\left(\frac{1}{2}\left(yf - (yf)^2 \omega\right)\right)
```
where ``\omega \sim \text{PG}(\omega\mid 1, 0)``, and PG is the Polya-Gamma distribution
See paper : [Efficient Gaussian Process Classification Using Polya-Gamma Data Augmentation](https://arxiv.org/abs/1802.06383)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/likelihood/logistic.jl#L1-L15">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.LogisticSoftMaxLikelihood" href="#AugmentedGaussianProcesses.LogisticSoftMaxLikelihood"><code>AugmentedGaussianProcesses.LogisticSoftMaxLikelihood</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p><strong>The Logistic-Softmax likelihood</strong></p><p>The multiclass likelihood with a logistic-softmax mapping: : <span>$p(y=i|\{f_k\}) = \sigma(f_i)/ \sum_k \sigma(f_k)$</span> where σ is the logistic function has the same properties as softmax.</p><hr/><p>For the analytical version, the likelihood is augmented multiple times to obtain :</p><div>\[#TODO\]</div><p>Paper with details under submission</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/likelihood/logisticsoftmax.jl#L1-L14">source</a></section><h2><a class="nav-anchor" id="Inference-Types-1" href="#Inference-Types-1">Inference Types</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.AnalyticVI" href="#AugmentedGaussianProcesses.AnalyticVI"><code>AugmentedGaussianProcesses.AnalyticVI</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Solve conjugate or conditionally conjugate likelihoods (especially valid for augmented likelihoods) </p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/inference/analyticVI.jl#L1">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.AnalyticSVI" href="#AugmentedGaussianProcesses.AnalyticSVI"><code>AugmentedGaussianProcesses.AnalyticSVI</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>AnalyticSVI(nMinibatch::Integer;ϵ::T=1e-5,optimizer::Optimizer=ALRSVI())</code></p><p>Return an <code>AnalyticVI{T}</code> object with stochastic updates, corresponding to Stochastic Variational Inference with analytical updates.</p><p><strong>Positional argument</strong></p><pre><code class="language-none">- `nMinibatch::Integer` : Number of samples per mini-batches</code></pre><p><strong>Keywords arguments</strong></p><pre><code class="language-none">- `ϵ::T` : convergence criteria, which can be user defined
- `optimizer::Optimizer` : Optimizer used for the variational updates. Should be an Optimizer object from the [GradDescent.jl]() package. Default is `ALRSVI()` (Adaptive Learning Rate for Stochastic Variational Inference)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/inference/analyticVI.jl#L36-L49">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.NumericalVI" href="#AugmentedGaussianProcesses.NumericalVI"><code>AugmentedGaussianProcesses.NumericalVI</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Solve any non-conjugate likelihood using Variational Inference by making a numerical approximation (quadrature or MC integration) of the expected log-likelihood ad its gradients</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/inference/numericalVI.jl#L1-L5">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.NumericalSVI" href="#AugmentedGaussianProcesses.NumericalSVI"><code>AugmentedGaussianProcesses.NumericalSVI</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>NumericalSVI(integration_technique::Symbol=:quad;ϵ::T=1e-5,nMC::Integer=1000,nGaussHermite::Integer=20,optimizer::Optimizer=Adam(α=0.1))</code></p><p>General constructor for Stochastic Variational Inference via numerical approximation.</p><p><strong>Argument</strong></p><pre><code class="language-none">-`nMinibatch::Integer` : Number of samples per mini-batches
-`integration_technique::Symbol` : Method of approximation can be `:quad` for quadrature see [QuadratureVI](@ref) or `:mcmc` for MCMC integration see [MCMCIntegrationVI](@ref)</code></pre><p><strong>Keyword arguments</strong></p><pre><code class="language-none">- `ϵ::T` : convergence criteria, which can be user defined
- `nMC::Int` : Number of samples per data point for the integral evaluation (for the MCMCIntegrationVI)
- `nGaussHermite::Int` : Number of points for the integral estimation (for the QuadratureVI)
- `optimizer::Optimizer` : Optimizer used for the variational updates. Should be an Optimizer object from the [GradDescent.jl]() package. Default is `Adam()`</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/inference/numericalVI.jl#L37-L53">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.QuadratureVI" href="#AugmentedGaussianProcesses.QuadratureVI"><code>AugmentedGaussianProcesses.QuadratureVI</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p><code>QuadratureVI(integration_technique::Symbol=:quad;ϵ::T=1e-5,nGaussHermite::Integer=20,optimizer::Optimizer=Adam(α=0.1))</code></p><p>Constructor for Variational Inference via quadrature approximation.</p><p><strong>Keyword arguments</strong></p><pre><code class="language-none">- `ϵ::T` : convergence criteria, which can be user defined
- `nGaussHermite::Int` : Number of points for the integral estimation (for the QuadratureVI)
- `optimizer::Optimizer` : Optimizer used for the variational updates. Should be an Optimizer object from the [GradDescent.jl]() package. Default is `Adam()`</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/inference/quadratureVI.jl#L23-L33">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.QuadratureSVI" href="#AugmentedGaussianProcesses.QuadratureSVI"><code>AugmentedGaussianProcesses.QuadratureSVI</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>QuadratureSVI(;ϵ::T=1e-5,nMC::Integer=1000,optimizer::Optimizer=Adam(α=0.1))</code></p><p>Constructor for Stochastic Variational Inference via quadrature approximation.</p><p><strong>Argument</strong></p><pre><code class="language-none">-`nMinibatch::Integer` : Number of samples per mini-batches</code></pre><p><strong>Keyword arguments</strong></p><pre><code class="language-none">- `ϵ::T` : convergence criteria, which can be user defined
- `nGaussHermite::Int` : Number of points for the integral estimation (for the QuadratureVI)
- `optimizer::Optimizer` : Optimizer used for the variational updates. Should be an Optimizer object from the [GradDescent.jl]() package. Default is `Adam()`</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/inference/quadratureVI.jl#L37-L51">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.MCMCIntegrationVI" href="#AugmentedGaussianProcesses.MCMCIntegrationVI"><code>AugmentedGaussianProcesses.MCMCIntegrationVI</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p><code>MCMCIntegrationVI(integration_technique::Symbol=:quad;ϵ::T=1e-5,nMC::Integer=1000,optimizer::Optimizer=Adam(α=0.1))</code></p><p>Constructor for Variational Inference via MCMC Integration approximation.</p><p><strong>Keyword arguments</strong></p><pre><code class="language-none">- `ϵ::T` : convergence criteria, which can be user defined
- `nMC::Int` : Number of samples per data point for the integral evaluation
- `optimizer::Optimizer` : Optimizer used for the variational updates. Should be an Optimizer object from the [GradDescent.jl]() package. Default is `Adam()`</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/inference/MCMCVI.jl#L22-L32">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.MCMCIntegrationSVI" href="#AugmentedGaussianProcesses.MCMCIntegrationSVI"><code>AugmentedGaussianProcesses.MCMCIntegrationSVI</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>MCMCIntegrationSVI(;ϵ::T=1e-5,nMC::Integer=1000,optimizer::Optimizer=Adam(α=0.1))</code></p><p>Constructor for Stochastic Variational Inference via MCMC integration approximation.</p><p><strong>Argument</strong></p><pre><code class="language-none">-`nMinibatch::Integer` : Number of samples per mini-batches</code></pre><p><strong>Keyword arguments</strong></p><pre><code class="language-none">- `ϵ::T` : convergence criteria, which can be user defined
- `nMC::Int` : Number of samples per data point for the integral evaluation
- `optimizer::Optimizer` : Optimizer used for the variational updates. Should be an Optimizer object from the [GradDescent.jl]() package. Default is `Adam()`</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/inference/MCMCVI.jl#L36-L50">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.GibbsSampling" href="#AugmentedGaussianProcesses.GibbsSampling"><code>AugmentedGaussianProcesses.GibbsSampling</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p><code>GibbsSampling(;ϵ::T=1e-5,nBurnin::Int=100,samplefrequency::Int=10)</code></p><p>Return a GibbsSampling{T} object to sample from the exact posterior distribution.</p><p><strong>Keywords arguments</strong></p><pre><code class="language-none">- `ϵ::T` : convergence criteria, which can be user defined
- `nBurnin::Int` : Number of samples discarded before starting to save samples
- `samplefrequency::Int` : Frequency of sampling</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/inference/gibbssampling.jl#L19-L29">source</a></section><h2><a class="nav-anchor" id="Functions-and-methods-1" href="#Functions-and-methods-1">Functions and methods</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.train!" href="#AugmentedGaussianProcesses.train!"><code>AugmentedGaussianProcesses.train!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>train!(model::AbstractGP;iterations::Integer=100,callback=0,conv_function=0)</code></p><p>Function to train the given GP <code>model</code>.</p><p><strong>Keyword Arguments</strong></p><p>there are options to change the number of max iterations,</p><ul><li><code>iterations::Int</code> : Number of iterations (not necessarily epochs!)for training</li><li><code>callback::Function</code> : Callback function called at every iteration. Should be of type <code>function(model,iter) ...  end</code></li><li><code>conv_function::Function</code> : Convergence function to be called every iteration, should return a scalar and take the same arguments as <code>callback</code></li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/training.jl#L2-L13">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.predict_f" href="#AugmentedGaussianProcesses.predict_f"><code>AugmentedGaussianProcesses.predict_f</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Compute the mean of the predicted latent distribution of <code>f</code> on <code>X_test</code> for the variational GP <code>model</code></p><p>Return also the variance if <code>covf=true</code> and the full covariance if <code>fullcov=true</code></p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/predictions.jl#L3-L7">source</a><div><div><p>Compute the mean of the predicted latent distribution of f on <code>X_test</code> for a sparse GP <code>model</code> Return also the variance if <code>covf=true</code> and the full covariance if <code>fullcov=true</code></p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/predictions.jl#L26-L29">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.predict_y" href="#AugmentedGaussianProcesses.predict_y"><code>AugmentedGaussianProcesses.predict_y</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>predict_y(model::AbstractGP{&lt;:RegressionLikelihood},X_test::AbstractMatrix)</code></p><p>Return the predictive mean of <code>X_test</code></p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/predictions.jl#L73-L77">source</a><div><div><p><code>predict_y(model::AbstractGP{&lt;:ClassificationLikelihood},X_test::AbstractMatrix)</code></p><p>Return the predicted most probable sign of <code>X_test</code></p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/predictions.jl#L82-L86">source</a><div><div><p><code>predict_y(model::AbstractGP{&lt;:MultiClassLikelihood},X_test::AbstractMatrix)</code></p><p>Return the predicted most probable class of <code>X_test</code></p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/predictions.jl#L91-L95">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.proba_y" href="#AugmentedGaussianProcesses.proba_y"><code>AugmentedGaussianProcesses.proba_y</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p><code>proba_y(model::AbstractGP,X_test::AbstractMatrix)</code></p><p>Return the probability distribution p(y<em>test|model,X</em>test) :</p><pre><code class="language-none">- Tuple of vectors of mean and variance for regression
- Vector of probabilities of y_test = 1 for binary classification
- Dataframe with columns and probability per class for multi-class classification</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/predictions.jl#L107-L115">source</a></section><h2><a class="nav-anchor" id="Kernels-1" href="#Kernels-1">Kernels</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.KernelModule.RBFKernel" href="#AugmentedGaussianProcesses.KernelModule.RBFKernel"><code>AugmentedGaussianProcesses.KernelModule.RBFKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Radial Basis Function Kernel also called RBF or SE(Squared Exponential)</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/kernels/RBF.jl#L1">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.KernelModule.MaternKernel" href="#AugmentedGaussianProcesses.KernelModule.MaternKernel"><code>AugmentedGaussianProcesses.KernelModule.MaternKernel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Matern Kernel</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/kernels/Matern.jl#L1-L3">source</a></section><h2><a class="nav-anchor" id="Kernel-functions-1" href="#Kernel-functions-1">Kernel functions</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.KernelModule.kernelmatrix" href="#AugmentedGaussianProcesses.KernelModule.kernelmatrix"><code>AugmentedGaussianProcesses.KernelModule.kernelmatrix</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Create the covariance matrix between the matrix X1 and X2 with the covariance function <code>kernel</code></p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/kernels/KernelMatrix.jl#L1">source</a><div><div><p>Compute the covariance matrix of the matrix X, optionally only compute the diagonal terms</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/kernels/KernelMatrix.jl#L19">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.KernelModule.kernelmatrix!" href="#AugmentedGaussianProcesses.KernelModule.kernelmatrix!"><code>AugmentedGaussianProcesses.KernelModule.kernelmatrix!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Compute the covariance matrix between the matrix X1 and X2 with the covariance function <code>kernel</code> in preallocated matrix K</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/kernels/KernelMatrix.jl#L8">source</a><div><div><p>Compute the covariance matrix of the matrix X in preallocated matrix K, optionally only compute the diagonal terms</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/kernels/KernelMatrix.jl#L30">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.KernelModule.getvariance" href="#AugmentedGaussianProcesses.KernelModule.getvariance"><code>AugmentedGaussianProcesses.KernelModule.getvariance</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Return the variance of the kernel</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/kernels/KernelModule.jl#L81">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="AugmentedGaussianProcesses.KernelModule.getlengthscales" href="#AugmentedGaussianProcesses.KernelModule.getlengthscales"><code>AugmentedGaussianProcesses.KernelModule.getlengthscales</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Return the lengthscale of the IsoKernel</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/kernels/KernelModule.jl#L86">source</a><div><div><p>Return the lengthscales of the ARD Kernel</p></div></div><a class="source-link" target="_blank" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/5365cc26461e412429788cf1c0dc0f09c6f93228/src/kernels/KernelModule.jl#L91">source</a></section><h2><a class="nav-anchor" id="Index-1" href="#Index-1">Index</a></h2><ul><li><a href="#AugmentedGaussianProcesses.AnalyticVI"><code>AugmentedGaussianProcesses.AnalyticVI</code></a></li><li><a href="#AugmentedGaussianProcesses.BayesianSVM"><code>AugmentedGaussianProcesses.BayesianSVM</code></a></li><li><a href="#AugmentedGaussianProcesses.GP"><code>AugmentedGaussianProcesses.GP</code></a></li><li><a href="#AugmentedGaussianProcesses.GaussianLikelihood"><code>AugmentedGaussianProcesses.GaussianLikelihood</code></a></li><li><a href="#AugmentedGaussianProcesses.GibbsSampling"><code>AugmentedGaussianProcesses.GibbsSampling</code></a></li><li><a href="#AugmentedGaussianProcesses.KernelModule.MaternKernel"><code>AugmentedGaussianProcesses.KernelModule.MaternKernel</code></a></li><li><a href="#AugmentedGaussianProcesses.KernelModule.RBFKernel"><code>AugmentedGaussianProcesses.KernelModule.RBFKernel</code></a></li><li><a href="#AugmentedGaussianProcesses.LogisticLikelihood"><code>AugmentedGaussianProcesses.LogisticLikelihood</code></a></li><li><a href="#AugmentedGaussianProcesses.LogisticSoftMaxLikelihood"><code>AugmentedGaussianProcesses.LogisticSoftMaxLikelihood</code></a></li><li><a href="#AugmentedGaussianProcesses.MCMCIntegrationVI"><code>AugmentedGaussianProcesses.MCMCIntegrationVI</code></a></li><li><a href="#AugmentedGaussianProcesses.NumericalVI"><code>AugmentedGaussianProcesses.NumericalVI</code></a></li><li><a href="#AugmentedGaussianProcesses.QuadratureVI"><code>AugmentedGaussianProcesses.QuadratureVI</code></a></li><li><a href="#AugmentedGaussianProcesses.SVGP"><code>AugmentedGaussianProcesses.SVGP</code></a></li><li><a href="#AugmentedGaussianProcesses.StudentTLikelihood"><code>AugmentedGaussianProcesses.StudentTLikelihood</code></a></li><li><a href="#AugmentedGaussianProcesses.VGP"><code>AugmentedGaussianProcesses.VGP</code></a></li><li><a href="#AugmentedGaussianProcesses.AnalyticSVI"><code>AugmentedGaussianProcesses.AnalyticSVI</code></a></li><li><a href="#AugmentedGaussianProcesses.KernelModule.getlengthscales"><code>AugmentedGaussianProcesses.KernelModule.getlengthscales</code></a></li><li><a href="#AugmentedGaussianProcesses.KernelModule.getvariance"><code>AugmentedGaussianProcesses.KernelModule.getvariance</code></a></li><li><a href="#AugmentedGaussianProcesses.KernelModule.kernelmatrix"><code>AugmentedGaussianProcesses.KernelModule.kernelmatrix</code></a></li><li><a href="#AugmentedGaussianProcesses.KernelModule.kernelmatrix!"><code>AugmentedGaussianProcesses.KernelModule.kernelmatrix!</code></a></li><li><a href="#AugmentedGaussianProcesses.MCMCIntegrationSVI"><code>AugmentedGaussianProcesses.MCMCIntegrationSVI</code></a></li><li><a href="#AugmentedGaussianProcesses.NumericalSVI"><code>AugmentedGaussianProcesses.NumericalSVI</code></a></li><li><a href="#AugmentedGaussianProcesses.QuadratureSVI"><code>AugmentedGaussianProcesses.QuadratureSVI</code></a></li><li><a href="#AugmentedGaussianProcesses.predict_f"><code>AugmentedGaussianProcesses.predict_f</code></a></li><li><a href="#AugmentedGaussianProcesses.predict_y"><code>AugmentedGaussianProcesses.predict_y</code></a></li><li><a href="#AugmentedGaussianProcesses.proba_y"><code>AugmentedGaussianProcesses.proba_y</code></a></li><li><a href="#AugmentedGaussianProcesses.train!"><code>AugmentedGaussianProcesses.train!</code></a></li></ul><footer><hr/><a class="previous" href="../comparison/"><span class="direction">Previous</span><span class="title">Other Julia GP Packages</span></a></footer></article></body></html>
